{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpEq92wQiElD",
        "outputId": "fa5b5fa0-2325-4a35-eea9-0c111cd60c13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Oct  4 14:04:15 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.20)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.12/dist-packages (1.5.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.23.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.35.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "# Check GPU\n",
        "!nvidia-smi\n",
        "\n",
        "# Install required packages\n",
        "!pip install timm einops torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4O-Kii7iFVK",
        "outputId": "e4a37fc7-8e10-42e9-e5c2-4f580b6f452b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "GPU: Tesla T4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 50000, Test: 10000\n",
            "Batches per epoch: 196\n",
            "Loading ViT-B/16...\n",
            "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 330M/330M [00:01<00:00, 181MB/s]\n",
            "/tmp/ipython-input-2654398520.py:132: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=CFG[\"use_amp\"])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded IMAGENET1K_V1 weights\n",
            "Trainable: 7,690 / 85,806,346 (0.0%)\n",
            "\n",
            "Training...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rE1/20:   0%|                                                                | 0/196 [00:00<?, ?it/s]/tmp/ipython-input-2654398520.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=CFG[\"use_amp\"]):\n",
            "Eval:   0%|                                                                  | 0/40 [00:00<?, ?it/s]/tmp/ipython-input-2654398520.py:197: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=CFG[\"use_amp\"]):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E 1: Loss=1.573 | Train=63.78% | Test=89.99% | LR=5.00e-05 <- BEST\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E 2: Loss=0.942 | Train=84.95% | Test=92.50% | LR=1.00e-04 <- BEST\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E 3: Loss=0.845 | Train=87.39% | Test=93.42% | LR=1.50e-04 <- BEST\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E 4: Loss=0.816 | Train=88.50% | Test=94.12% | LR=1.50e-04 <- BEST\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E 5: Loss=0.799 | Train=89.18% | Test=94.32% | LR=1.49e-04 <- BEST\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E 6: Loss=0.789 | Train=89.59% | Test=94.38% | LR=1.45e-04 <- BEST\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E 7: Loss=0.784 | Train=89.79% | Test=94.62% | LR=1.39e-04 <- BEST\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E 8: Loss=0.777 | Train=90.10% | Test=94.75% | LR=1.30e-04 <- BEST\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E 9: Loss=0.778 | Train=90.00% | Test=94.82% | LR=1.20e-04 <- BEST\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E10: Loss=0.774 | Train=90.30% | Test=94.89% | LR=1.08e-04 <- BEST\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E11: Loss=0.770 | Train=90.52% | Test=94.93% | LR=9.55e-05 <- BEST\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E12: Loss=0.768 | Train=90.53% | Test=95.02% | LR=8.19e-05 <- BEST\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E13: Loss=0.767 | Train=90.68% | Test=95.06% | LR=6.81e-05 <- BEST\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E14/20:  94%|█████████████████▊ | 184/196 [05:49<00:17,  1.43s/it, loss=0.809, acc=90.8%, grad=0.48]"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Configuration for maximum accuracy\n",
        "CFG = {\n",
        "    \"epochs\": 20,\n",
        "    \"batch_size\": 256,  \n",
        "    \"lr\": 1.5e-4,      \n",
        "    \"weight_decay\": 0.01,\n",
        "    \"num_workers\": 4,\n",
        "    \"seed\": 42,\n",
        "    \"use_amp\": True,\n",
        "    \"patience\": 6,\n",
        "    \"label_smoothing\": 0.1,\n",
        "    \"warmup_epochs\": 3,\n",
        "    \"grad_clip\": 2.0,   \n",
        "}\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Enable cuDNN benchmark for fixed input sizes\n",
        "if device == \"cuda\":\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    if device == \"cuda\":\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(CFG[\"seed\"])\n",
        "\n",
        "# Precompiled transforms (cached, not rebuilt each call)\n",
        "TRANSFORM_TRAIN = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomCrop(224, padding=32, padding_mode='reflect'),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    transforms.RandomErasing(p=0.3, scale=(0.02, 0.25)),\n",
        "])\n",
        "\n",
        "TRANSFORM_TEST = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=TRANSFORM_TRAIN)\n",
        "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=TRANSFORM_TEST)\n",
        "\n",
        "# Increased batch size + persistent workers\n",
        "trainloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=CFG[\"batch_size\"],\n",
        "    shuffle=True,\n",
        "    num_workers=CFG[\"num_workers\"],\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True,\n",
        "    prefetch_factor=2  # Prefetch batches for faster loading\n",
        ")\n",
        "testloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=CFG[\"batch_size\"],\n",
        "    shuffle=False,\n",
        "    num_workers=CFG[\"num_workers\"],\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True,\n",
        "    prefetch_factor=2\n",
        ")\n",
        "\n",
        "print(f\"Train: {len(train_dataset)}, Test: {len(test_dataset)}\")\n",
        "print(f\"Batches per epoch: {len(trainloader)}\")\n",
        "\n",
        "# Simplified model loading\n",
        "print(\"Loading ViT-B/16...\")\n",
        "try:\n",
        "    model = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n",
        "    print(\"Loaded IMAGENET1K_V1 weights\")\n",
        "except AttributeError:\n",
        "    model = vit_b_16(weights='DEFAULT')\n",
        "    print(\"Loaded DEFAULT weights\")\n",
        "\n",
        "in_features = model.heads.head.in_features\n",
        "model.heads = nn.Sequential(nn.Dropout(0.1), nn.Linear(in_features, 10))\n",
        "\n",
        "# Selective parameter freezing with parameter groups\n",
        "backbone_params = []\n",
        "head_params = []\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    param.requires_grad = False\n",
        "    # Unfreeze last 3 encoder blocks\n",
        "    if any(f\"encoder.layers.{i}.\" in name for i in [9, 10, 11]):\n",
        "        param.requires_grad = True\n",
        "        backbone_params.append(param)\n",
        "    # Unfreeze head\n",
        "    elif \"heads\" in name:\n",
        "        param.requires_grad = True\n",
        "        head_params.append(param)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Trainable: {trainable:,} / {total:,} ({100*trainable/total:.1f}%)\")\n",
        "\n",
        "# Parameter groups with different learning rates\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=CFG[\"label_smoothing\"])\n",
        "\n",
        "# Use of different LRs for backbone vs head (head learns faster)\n",
        "optimizer = optim.AdamW([\n",
        "    {'params': backbone_params, 'lr': CFG[\"lr\"], 'weight_decay': CFG[\"weight_decay\"]},\n",
        "    {'params': head_params, 'lr': CFG[\"lr\"] * 2, 'weight_decay': CFG[\"weight_decay\"] * 0.5}\n",
        "], betas=(0.9, 0.999), eps=1e-8)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=CFG[\"use_amp\"])\n",
        "\n",
        "# Combined warmup + cosine annealing\n",
        "def get_lr(epoch):\n",
        "    if epoch < CFG[\"warmup_epochs\"]:\n",
        "        return (epoch + 1) / CFG[\"warmup_epochs\"]\n",
        "    progress = (epoch - CFG[\"warmup_epochs\"]) / (CFG[\"epochs\"] - CFG[\"warmup_epochs\"])\n",
        "    return max(0.001, 0.5 * (1.0 + np.cos(np.pi * progress)))\n",
        "\n",
        "scheduler = optim.lr_scheduler.LambdaLR(optimizer, get_lr)\n",
        "\n",
        "def train_epoch(epoch):\n",
        "    model.train()\n",
        "    total, correct, loss_sum = 0, 0, 0.0\n",
        "\n",
        "    # Reduced logging overhead with leave=False\n",
        "    pbar = tqdm(trainloader, desc=f\"E{epoch+1}/{CFG['epochs']}\", leave=False, ncols=100)\n",
        "\n",
        "    for imgs, labels in pbar:\n",
        "        imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "        # Zero grad with set_to_none for memory efficiency\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        # AMP for all forward/backward ops\n",
        "        with torch.cuda.amp.autocast(enabled=CFG[\"use_amp\"]):\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        # Scaled backward pass\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        # Gradient clipping after unscaling\n",
        "        scaler.unscale_(optimizer)\n",
        "        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), CFG[\"grad_clip\"])\n",
        "\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # Metrics\n",
        "        loss_sum += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        if total % 1000 == 0:\n",
        "            pbar.set_postfix({\n",
        "                'loss': f'{loss.item():.3f}',\n",
        "                'acc': f'{100.*correct/total:.1f}%',\n",
        "                'grad': f'{grad_norm:.2f}'\n",
        "            })\n",
        "\n",
        "    return loss_sum / len(trainloader), 100.*correct/total\n",
        "\n",
        "def evaluate():\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in tqdm(testloader, desc=\"Eval\", leave=False, ncols=100):\n",
        "            imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "            with torch.cuda.amp.autocast(enabled=CFG[\"use_amp\"]):\n",
        "                outputs = model(imgs)\n",
        "\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return 100.*correct/total, np.array(all_preds), np.array(all_labels)\n",
        "\n",
        "# Training loop\n",
        "print(\"\\nTraining...\\n\")\n",
        "best_acc, patience = 0.0, 0\n",
        "history = {'train_loss': [], 'train_acc': [], 'test_acc': [], 'lr': []}\n",
        "\n",
        "for epoch in range(CFG[\"epochs\"]):\n",
        "    train_loss, train_acc = train_epoch(epoch)\n",
        "    test_acc, preds, labels = evaluate()\n",
        "\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    scheduler.step()\n",
        "\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['test_acc'].append(test_acc)\n",
        "    history['lr'].append(current_lr)\n",
        "\n",
        "    print(f\"E{epoch+1:2d}: Loss={train_loss:.3f} | Train={train_acc:.2f}% | Test={test_acc:.2f}% | LR={current_lr:.2e}\", end=\"\")\n",
        "\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        patience = 0\n",
        "        # Saving only essential state\n",
        "        torch.save({\n",
        "            'model': model.state_dict(),\n",
        "            'acc': test_acc,\n",
        "            'epoch': epoch\n",
        "        }, \"best_vit_cifar10.pth\")\n",
        "        print(\" <- BEST\")\n",
        "    else:\n",
        "        patience += 1\n",
        "        print(f\" (patience {patience}/{CFG['patience']})\")\n",
        "\n",
        "    if patience >= CFG[\"patience\"]:\n",
        "        print(f\"\\nEarly stop at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "print(f\"\\nBest Test Accuracy: {best_acc:.2f}%\")\n",
        "\n",
        "#  Conditional visualization (only at end)\n",
        "print(\"\\nGenerating results...\")\n",
        "checkpoint = torch.load(\"best_vit_cifar10.pth\")\n",
        "model.load_state_dict(checkpoint['model'])\n",
        "final_acc, final_preds, final_labels = evaluate()\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(final_labels, final_preds)\n",
        "class_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. Confusion matrix\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names,\n",
        "            yticklabels=class_names, ax=axes[0, 0], cbar_kws={'label': 'Count'})\n",
        "axes[0, 0].set_title(f'Confusion Matrix (Acc: {best_acc:.2f}%)', fontweight='bold')\n",
        "axes[0, 0].set_ylabel('True')\n",
        "axes[0, 0].set_xlabel('Predicted')\n",
        "\n",
        "# 2. Training curves\n",
        "axes[0, 1].plot(history['train_acc'], label='Train', linewidth=2, marker='o', markersize=4)\n",
        "axes[0, 1].plot(history['test_acc'], label='Test', linewidth=2, marker='s', markersize=4)\n",
        "axes[0, 1].axhline(y=best_acc, color='green', linestyle='--', label=f'Best: {best_acc:.2f}%')\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('Accuracy (%)')\n",
        "axes[0, 1].set_title('Accuracy Curves', fontweight='bold')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Loss curve\n",
        "axes[1, 0].plot(history['train_loss'], linewidth=2, color='red', marker='o', markersize=4)\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('Loss')\n",
        "axes[1, 0].set_title('Training Loss', fontweight='bold')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Learning rate schedule\n",
        "axes[1, 1].plot(history['lr'], linewidth=2, color='purple', marker='o', markersize=4)\n",
        "axes[1, 1].set_xlabel('Epoch')\n",
        "axes[1, 1].set_ylabel('Learning Rate')\n",
        "axes[1, 1].set_title('LR Schedule', fontweight='bold')\n",
        "axes[1, 1].set_yscale('log')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('vit_cifar10_results.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved: vit_cifar10_results.png\")\n",
        "\n",
        "# Per-class accuracy\n",
        "class_correct = [0] * 10\n",
        "class_total = [0] * 10\n",
        "for pred, true in zip(final_preds, final_labels):\n",
        "    class_total[true] += 1\n",
        "    if pred == true:\n",
        "        class_correct[true] += 1\n",
        "\n",
        "print(\"\\nPer-Class Accuracy:\")\n",
        "print(\"-\" * 35)\n",
        "for i, name in enumerate(class_names):\n",
        "    acc = 100 * class_correct[i] / class_total[i]\n",
        "    print(f\"{name:8s}: {acc:5.2f}% ({class_correct[i]}/{class_total[i]})\")\n",
        "print(\"-\" * 35)\n",
        "print(f\"Overall: {best_acc:.2f}%\")\n",
        "\n",
        "# Summary\n",
        "print(\"\\nOptimizations Applied:\")\n",
        "print(\"- Precompiled transforms (cached)\")\n",
        "print(\"- Batch size 256 (increased GPU utilization)\")\n",
        "print(\"- Parameter groups (different LRs for backbone/head)\")\n",
        "print(\"- cuDNN benchmark enabled\")\n",
        "print(\"- Prefetch factor 2 (faster data loading)\")\n",
        "print(\"- Gradient norm tracking\")\n",
        "print(\"- Reduced logging overhead\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
